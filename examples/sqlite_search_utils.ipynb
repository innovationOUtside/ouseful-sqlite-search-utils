{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c2870d",
   "metadata": {},
   "source": [
    "# SQLite Search Utilities (`ouseful_sqlite_search_utils`)\n",
    "\n",
    "Custom functions providing additional search utilities over text documents in SQLite databases.\n",
    "\n",
    "Functions are defined that return:\n",
    "\n",
    "- scalar values (`get_fragment()`m `get_longest_common_substring()`);\n",
    "- aggregations (`join_sentences()`);\n",
    "- tables (`get_sentences()`, `get_paragraphs()`, `re_search()`, `regex_search(`, `find_near_matches_all()`, `find_fuzzy_matches(`))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988c5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade git+https://github.com/innovationOUtside/ouseful-sqlite-search-utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca086c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"sqlite_search_demo.db\"\n",
    "\n",
    "# While developing the script, recreate database each time...\n",
    "db = Database(db_name, recreate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e3fee",
   "metadata": {},
   "source": [
    "## Snippets functions\n",
    "\n",
    "Functions that search deep into a text record and return snippets or chunked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba7fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ouseful_sqlite_search_utils import snippets\n",
    "\n",
    "snippets.register_snippets(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51150048",
   "metadata": {},
   "source": [
    "### `get_sentences(start_index, end_index, text)`\n",
    "\n",
    "This function will return one or more sentences, one sentence per row, starting index of 1, based on sentence count within the returned document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3923706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table sentences (id, txt)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"sentences\"].insert({\"id\":1, \"txt\": \"This is sentence 1. This is sentence 2. This is sentence 3.\"})\n",
    "db[\"sentences\"].insert({\"id\":2, \"txt\": \"This is sentence 4.\"})\n",
    "db[\"sentences\"].insert({\"id\":3, \"txt\": \"This is sentence 5. This is sentence 6.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077df094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'sentence': 'This is sentence 1.'}\n",
      "{'id': 2, 'sentence': 'This is sentence 4.'}\n",
      "{'id': 3, 'sentence': 'This is sentence 5.'}\n"
     ]
    }
   ],
   "source": [
    "# Return just the first sentence\n",
    "for i in db.query(\"SELECT id, sentence FROM sentences, get_sentences(1, 1, sentences.txt)\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416b5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'sentence': 'This is sentence 2.'}\n",
      "{'id': 1, 'sentence': 'This is sentence 3.'}\n",
      "{'id': 3, 'sentence': 'This is sentence 6.'}\n"
     ]
    }
   ],
   "source": [
    "# Return second and third sentences\n",
    "for i in db.query(\"SELECT id, sentence FROM sentences, get_sentences(2, 3, sentences.txt)\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec92788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'sentence': 'This is sentence 3.'}\n",
      "{'id': 2, 'sentence': 'This is sentence 4.'}\n",
      "{'id': 3, 'sentence': 'This is sentence 6.'}\n"
     ]
    }
   ],
   "source": [
    "# Get the last sentence\n",
    "q = \"\"\"\n",
    "SELECT id, sentence\n",
    "FROM sentences, get_sentences(-1, NULL, sentences.txt)\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb454f3",
   "metadata": {},
   "source": [
    "## `join_sentences()`\n",
    "\n",
    "This aggregation function will join two or more sentences returned in a table from `get_sentences()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59e6f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'sentence_join(sentence)': 'This is sentence 2. This is sentence 3.'}\n",
      "{'id': 3, 'sentence_join(sentence)': 'This is sentence 6.'}\n"
     ]
    }
   ],
   "source": [
    "# Return second and third sentences and join them together\n",
    "q = \"\"\"\n",
    "SELECT id, join_sentences(sentence)\n",
    "FROM sentences, get_sentences(2, 3, sentences.txt)\n",
    "GROUP BY id\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdd3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fragment(text, startend):\n",
    "    \"\"\"Return substring from a text based on start and end substrings delimited by ::.\"\"\"\n",
    "    startend = startend.split(\"::\")\n",
    "    if startend[0] not in text or startend[1] not in text:\n",
    "        return\n",
    "\n",
    "    start_idx = text.index(startend[0])\n",
    "    end_idx = text.index(startend[1])\n",
    "    \n",
    "    if end_idx < start_idx:\n",
    "        return\n",
    "\n",
    "    return text[start_idx: end_idx+len(startend[1])]\n",
    "\n",
    "db.conn.create_function(\"get_fragment\", 2, get_fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d47718",
   "metadata": {},
   "source": [
    "## `get_paragraphs()`\n",
    "\n",
    "Split the text into paragraphs and return the specified range of paragraphs (initial index is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc747a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table paragraphs (id, txt)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"paragraphs\"].insert({\"id\":1, \"txt\": \"This is sentence 1, para 1. This is sentence 2.\\n\\nThis is sentence 3, para 2.\"})\n",
    "db[\"paragraphs\"].insert({\"id\":2, \"txt\": \"This is sentence 1, para 1.\"})\n",
    "db[\"paragraphs\"].insert({\"id\":3, \"txt\": \"This is sentence 1, para 1.\\n\\nThis is sentence 1, para 2.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151b2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'paragraph': 'This is sentence 3, para 2.'}\n",
      "{'id': 3, 'paragraph': 'This is sentence 1, para 2.'}\n"
     ]
    }
   ],
   "source": [
    "# Return just the second paragraph\n",
    "for i in db.query(\"SELECT id, paragraph FROM paragraphs, get_paragraphs(2, 2, paragraphs.txt)\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20425f1e",
   "metadata": {},
   "source": [
    "## `get_fragment()`\n",
    "\n",
    "Get a fragment between a start and end phrase separated by `::`.\n",
    "\n",
    "Note - if the start or end phrase is not unique, the first recorded match will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c435680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fragment': 'Start he'}\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT get_fragment(\"nce 2::sentence 1\", txt)\n",
    "FROM sentences\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(\"SELECT get_fragment('Start here. This is the end. To here.', 'Start::he') AS fragment\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ed7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_fragment(\"nce 2::sentence 1\", txt)': None}\n",
      "{'get_fragment(\"nce 2::sentence 1\", txt)': None}\n",
      "{'get_fragment(\"nce 2::sentence 1\", txt)': None}\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT get_fragment(\"nce 2::sentence 1\", txt)\n",
    "FROM sentences\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68736bbc",
   "metadata": {},
   "source": [
    "### `get_longest_common_substring()`\n",
    "\n",
    "Get the longest common substring across two records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23b5201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'common': 'This is sentence '}\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT get_longest_common_substring('This is sentence 1.', 'This is sentence 4.') AS common\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd24070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id1': 1, 'id2': 2, 'get_longest_common_substring(txt1.txt, txt2.txt)': 'This is sentence '}\n",
      "{'id1': 1, 'id2': 3, 'get_longest_common_substring(txt1.txt, txt2.txt)': '. This is sentence '}\n",
      "{'id1': 2, 'id2': 3, 'get_longest_common_substring(txt1.txt, txt2.txt)': 'This is sentence '}\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT txt1.id AS id1, txt2.id AS id2, get_longest_common_substring(txt1.txt, txt2.txt)\n",
    "FROM sentences AS txt1, sentences AS txt2\n",
    "WHERE txt1.id < txt2.id\n",
    "\"\"\"\n",
    "\n",
    "for i in db.query(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc2d48",
   "metadata": {},
   "source": [
    "## Partial Matches\n",
    "\n",
    "As well as retrieving records based on matching search terms exactly against elements contained the database, we can also make use of fuzzy search functions to identify partially or fuzzily matched items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096f8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ouseful_sqlite_search_utils import partial\n",
    "\n",
    "partial.register_partials(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c77ef",
   "metadata": {},
   "source": [
    "### `re_search()`\n",
    "\n",
    "To start with, we can use a simple Python regualr expression matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c77055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'sentence 1')\n",
      "(1, 'sentence 2')\n",
      "(1, 'sentence 3')\n",
      "(2, 'sentence 4')\n",
      "(3, 'sentence 5')\n",
      "(3, 'sentence 6')\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT id, re.* FROM sentences, re_search('sentence \\d+', sentences.txt) AS re\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0c6279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sentence 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>sentence 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>sentence 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       match\n",
       "0   1  sentence 1\n",
       "1   1  sentence 2\n",
       "2   1  sentence 3\n",
       "3   2  sentence 4\n",
       "4   3  sentence 5\n",
       "5   3  sentence 6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_sql\n",
    "\n",
    "read_sql(q, db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49348d0a",
   "metadata": {},
   "source": [
    "### `regex_search()`\n",
    "\n",
    "The [`regex`](https://github.com/mrabarnett/mrab-regex) package offers a wider range of regular expression matching rules, including the ability [partially match](https://github.com/mrabarnett/mrab-regex#added-partial-matches-hg-issue-102) expressions. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "967f5373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table partial (id, txt)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"partial\"].insert({\"id\":1, \"txt\": \"The bin eater is...\"})\n",
    "db[\"partial\"].insert({\"id\":2, \"txt\": \"The in eater is...\"})\n",
    "db[\"partial\"].insert({\"id\":3, \"txt\": \"The bin eater is...\"})\n",
    "db[\"partial\"].insert({\"id\":4, \"txt\": \"The bin eating tradition is...\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c00ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'e bin eater', 2, 13)\n",
      "(2, 'he in eater', 1, 12)\n",
      "(3, 'e bin eater', 2, 13)\n",
      "(4, 'bin eatin', 4, 13)\n"
     ]
    }
   ],
   "source": [
    "# Detect  particular number of single character errors\n",
    "q = \"\"\"\n",
    "SELECT id, reg.* FROM partial, regex_search('(sin eater){e<=3}', partial.txt) AS reg\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf9bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'in eater', 5, 13)\n",
      "(2, 'in eater', 4, 12)\n",
      "(3, 'in eater', 5, 13)\n"
     ]
    }
   ],
   "source": [
    "# Detect  particular number of single character deletions\n",
    "q = \"\"\"\n",
    "SELECT id, reg.* FROM partial, regex_search('(sin eater){d<=1}', partial.txt) AS reg\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55de6df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'bin eater', 4, 13)\n",
      "(2, ' in eater', 3, 12)\n",
      "(3, 'bin eater', 4, 13)\n"
     ]
    }
   ],
   "source": [
    "# Detect  particular number of single character substitutions\n",
    "q = \"\"\"\n",
    "SELECT id, reg.* FROM partial, regex_search('(sin eater){s<=1}', partial.txt) AS reg\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(q):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230fa88",
   "metadata": {},
   "source": [
    "### `find_near_matches()`\n",
    "\n",
    "The `find_near_matches()` function uses the `fuzzysearch.find_near_matches()` to partially match the query string against records that occur in the database. If there are multiple matches, only the first match is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c8c684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'txt': 'The bin eater is...', 'fuzzy': 'bin eater'}\n",
      "{'id': 2, 'txt': 'The in eater is...', 'fuzzy': 'in eater'}\n",
      "{'id': 3, 'txt': 'The bin eater is...', 'fuzzy': 'bin eater'}\n",
      "{'id': 4, 'txt': 'The bin eating tradition is...', 'fuzzy': 'bin eatin'}\n"
     ]
    }
   ],
   "source": [
    "for i in db.query(\"SELECT id, txt, find_near_matches('bin eater', partial.txt) AS fuzzy FROM partial\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f26397",
   "metadata": {},
   "source": [
    "### `find_near_matches_all()`\n",
    "\n",
    "The `find_near_matches_all()` uses the `fuzzysearch.find_near_matches()` to partially match the query string against records that occur in the database. If there are multiple matches, they are all returned as a table, one result per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b74f28b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'txt': 'The bin eater is...', 'matched': 'bin eater', 'start': 4, 'end': 13, 'dist': 1}\n",
      "{'id': 2, 'txt': 'The in eater is...', 'matched': ' in eater', 'start': 3, 'end': 12, 'dist': 1}\n",
      "{'id': 3, 'txt': 'The bin eater is...', 'matched': 'bin eater', 'start': 4, 'end': 13, 'dist': 1}\n"
     ]
    }
   ],
   "source": [
    "for i in db.query(\"SELECT * FROM partial, find_near_matches_all('sin eater', partial.txt, 2)\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48934d0b",
   "metadata": {},
   "source": [
    "### `find_fuzzy_matches()`\n",
    "\n",
    "The `find_fuzzy_matches()` function uses the `FuzzyMatcher` function from the `spaczz` package that adds fuzzy matching to `spacy` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a78c1e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'matched': 'The bin eater is...',\n",
       "  'start': 1,\n",
       "  'end': 3,\n",
       "  'fragment': 'bin eater',\n",
       "  'ratio': 89},\n",
       " {'matched': 'The in eater is...',\n",
       "  'start': 1,\n",
       "  'end': 3,\n",
       "  'fragment': 'in eater',\n",
       "  'ratio': 94},\n",
       " {'matched': 'The bin eater is...',\n",
       "  'start': 1,\n",
       "  'end': 3,\n",
       "  'fragment': 'bin eater',\n",
       "  'ratio': 89}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_q = f\"\"\"\n",
    "SELECT fz.*\n",
    "FROM partial, find_fuzzy_matches('sin eater', partial.txt) AS fz ;\n",
    "\"\"\"\n",
    "\n",
    "list(db.query(_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ece3eb",
   "metadata": {},
   "source": [
    "## Spell-Checking\n",
    "\n",
    "We can also run a spell-checker against the database, and return records with typographical errors highlighted.\n",
    "\n",
    "*This currently runs using an `en-US` language pack.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fff3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ouseful_sqlite_search_utils import spellcheck\n",
    "\n",
    "spellcheck.register_partials(db.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfb0a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This sentence is fine. A sentence with <span style=\"color:red\">a</span> error in the Hitchhiker’s Guide tot he ...',)\n",
      "('... with a error in the Hitchhiker’s Guide <span style=\"color:red\">tot he</span> Galaxy',)\n"
     ]
    }
   ],
   "source": [
    "text = 'This sentence is fine. A sentence with a error in the Hitchhiker’s Guide tot he Galaxy'\n",
    "\n",
    "for i in db.execute(f'SELECT * FROM typo_highlighter(\"{text}\");'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffcf7c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('There is <span style=\"color:red\">a</span> apeling error here. This is okay. Theze...',)\n",
      "('There is a <span style=\"color:red\">apeling</span> error here. This is okay. Theze a coupl...',)\n",
      "('... is a apeling error here. This is okay. <span style=\"color:red\">Theze</span> a coupl spelling erros here.',)\n",
      "('...eling error here. This is okay. Theze a <span style=\"color:red\">coupl</span> spelling erros here.',)\n",
      "('...e. This is okay. Theze a coupl spelling <span style=\"color:red\">erros</span> here.',)\n"
     ]
    }
   ],
   "source": [
    "text = 'There is a apeling error here. This is okay. Theze a coupl spelling erros here.'\n",
    "\n",
    "for i in db.execute(f'SELECT * FROM typo_highlighter(\"{text}\");'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93251020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table typos (id, txt)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"typos\"].insert({\"id\":1, \"txt\": \"There is a apeling error here.\"})\n",
    "db[\"typos\"].insert({\"id\":2, \"txt\": \"This is okay.\"})\n",
    "db[\"typos\"].insert({\"id\":3, \"txt\": \"Theze a coupl spelling erros here.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a99fac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'There is a apeling error here.', 'There is <span style=\"color:red\">a</span> apeling error here.')\n",
      "(1, 'There is a apeling error here.', 'There is a <span style=\"color:red\">apeling</span> error here.')\n",
      "(3, 'Theze a coupl spelling erros here.', '<span style=\"color:red\">Theze</span> a coupl spelling erros here.')\n",
      "(3, 'Theze a coupl spelling erros here.', 'Theze a <span style=\"color:red\">coupl</span> spelling erros here.')\n",
      "(3, 'Theze a coupl spelling erros here.', 'Theze a coupl spelling <span style=\"color:red\">erros</span> here.')\n"
     ]
    }
   ],
   "source": [
    "for i in db.execute(f'SELECT * FROM typos, typo_highlighter(typos.txt);'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d172266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
